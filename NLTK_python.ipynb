{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLTK-python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN+VseMBd3ZxdDXf7M4GaF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaifAlmaliki/NLTK_python/blob/main/NLTK_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9TYSm7iMClh",
        "outputId": "dbc42551-8465-4be5-f0fe-22a02d3c98a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcvH8GA1MT85"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVndlfG-MZvl",
        "outputId": "d14747f9-ba32-4013-f695-7a6906cabc16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# Library to Tokenize by punkt\n",
        "nltk.download('punkt')  \n",
        "\n",
        "# Library to Tokenize by wordnet\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Library to Tokenize by stopword\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Library to Tokenize by POS TAG\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU-OpMZjPWSU"
      },
      "source": [
        "**1. NLTK Sentence Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "souPcPwdNZtk"
      },
      "source": [
        "myText=\"Today is a great day. It is even better than yesterday. And yesterday was the best day ever.\""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHU27oSqNBcI",
        "outputId": "6582ca23-993b-4cf2-a0aa-e053a605068c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Letâ€™s try tokenizing a sentence.\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(myText)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Today is a great day.',\n",
              " 'It is even better than yesterday.',\n",
              " 'And yesterday was the best day ever.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fneoll3aOD67",
        "outputId": "e34b9e64-f031-417e-ff07-615c19e3e268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Another test sentence\n",
        "sent_tokenize(\"Hi, how are you? I'm good, you? Great!\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi, how are you?', \"I'm good, you?\", 'Great!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LYmdR8kObCZ",
        "outputId": "5e752074-7ae3-45d9-c706-44fb4b76d879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Another test sentence\n",
        "nltk.sent_tokenize(\"Last night, I went to Mrs. Martinez's housewarming. It was a disaster.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Last night, I went to Mrs. Martinez's housewarming.\", 'It was a disaster.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QJyyJLSPDEN",
        "outputId": "caf5173a-fe2d-44a0-bd34-755428ff8950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# One issue we face while tokenizing is abbreviations\n",
        "# That was supposed to be one complete sentence it split into two.\n",
        "sent_tokenize(\"She holds an MDS. in Oral Pathology\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['She holds an MDS.', 'in Oral Pathology']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "475ONwItPNp7"
      },
      "source": [
        "**2. NLTK Word Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2DSh_35PQOh",
        "outputId": "fc317ee8-4f1b-424d-e46a-52867360158e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "nltk.word_tokenize(myText)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Today',\n",
              " 'is',\n",
              " 'a',\n",
              " 'great',\n",
              " 'day',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'even',\n",
              " 'better',\n",
              " 'than',\n",
              " 'yesterday',\n",
              " '.',\n",
              " 'And',\n",
              " 'yesterday',\n",
              " 'was',\n",
              " 'the',\n",
              " 'best',\n",
              " 'day',\n",
              " 'ever',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgpTK1qtPv5b",
        "outputId": "b8ed02b4-0ac9-40ce-95b2-520e3ca201b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "nltk.word_tokenize(\"Last night, I went to Mrs. Martinez's housewarming. It was a disaster.\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Last',\n",
              " 'night',\n",
              " ',',\n",
              " 'I',\n",
              " 'went',\n",
              " 'to',\n",
              " 'Mrs.',\n",
              " 'Martinez',\n",
              " \"'s\",\n",
              " 'housewarming',\n",
              " '.',\n",
              " 'It',\n",
              " 'was',\n",
              " 'a',\n",
              " 'disaster',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipbMdtMLZX7R"
      },
      "source": [
        "**Find Synonyms From NLTK WordNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8cpWy5-P7F2",
        "outputId": "0d31bd7d-6d50-4e47-f293-43ec6f788a5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "# WordNet is an NLP database with synonyms, antonyms, and brief definitions.\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "syn  = wordnet.synsets('study')\n",
        "syn"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('survey.n.01'),\n",
              " Synset('study.n.02'),\n",
              " Synset('report.n.01'),\n",
              " Synset('study.n.04'),\n",
              " Synset('study.n.05'),\n",
              " Synset('discipline.n.01'),\n",
              " Synset('sketch.n.01'),\n",
              " Synset('cogitation.n.02'),\n",
              " Synset('study.n.09'),\n",
              " Synset('study.n.10'),\n",
              " Synset('analyze.v.01'),\n",
              " Synset('study.v.02'),\n",
              " Synset('study.v.03'),\n",
              " Synset('learn.v.04'),\n",
              " Synset('study.v.05'),\n",
              " Synset('study.v.06')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeufYYXfQ8YX",
        "outputId": "05388a73-bdd3-44bd-c94a-5b72a02b56ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "# brief definitions\n",
        "\n",
        "syn[4].definition()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a room used for reading and writing and studying'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz4Ya072RM5i",
        "outputId": "6d0e1d45-83ff-4db4-a5d8-101fd9a0f031",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "syn[5].examples()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in what discipline is his doctorate?',\n",
              " 'teachers should be well trained in their subject',\n",
              " 'anthropology is the study of human beings']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrY-h3tjRq6_",
        "outputId": "b1a3d437-1421-427b-a5e0-bbb3b721d7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "# DO you know the meaning of 'Life'\n",
        "syn = wordnet.synsets('life')\n",
        "syn[0].definition()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a characteristic state or mode of living'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIny095ZR81G",
        "outputId": "99d5e05e-ed41-4706-a826-52acc8b15a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "syn[0].examples()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['social life', 'city life', 'real life']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HypBLbV-SEec",
        "outputId": "092238c4-dd44-46b6-d18d-1a507fa5cae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "syn=wordnet.synsets('AI')\n",
        "syn"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('army_intelligence.n.01'),\n",
              " Synset('artificial_intelligence.n.01'),\n",
              " Synset('three-toed_sloth.n.01'),\n",
              " Synset('artificial_insemination.n.01')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFf8yc6QSJVt",
        "outputId": "f530499e-8363-4f14-e220-5f87e7747f67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "syn[1].definition()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the branch of computer science that deal with writing computer programs that can solve problems creatively'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zv8ffCHBSSIj",
        "outputId": "5161d9e8-ae20-423f-faac-fe64330e8318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "syn[1].examples()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['workers in AI hope to imitate or duplicate intelligence in computers and robots']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7uEMXKNSacU",
        "outputId": "1bdc28e3-fff1-40a4-86c5-02de0348f03b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "# To get the list of synonyms:\n",
        "synonyms = []\n",
        "for syn in wordnet.synsets('AI'):\n",
        "  for lemma in syn.lemmas():\n",
        "    synonyms.append(lemma.name())\n",
        "synonyms"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Army_Intelligence',\n",
              " 'AI',\n",
              " 'artificial_intelligence',\n",
              " 'AI',\n",
              " 'three-toed_sloth',\n",
              " 'ai',\n",
              " 'Bradypus_tridactylus',\n",
              " 'artificial_insemination',\n",
              " 'AI']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVh6ir1CZg6J"
      },
      "source": [
        "**Find Antonyms From NLTK WordNet**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbOjGMDAZfKR",
        "outputId": "cc58ad4c-5764-451b-d84c-0e46ddb221b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# To get the list of antonyms, we first need to check the lemmas- are there antonyms?\n",
        "from nltk.corpus import  wordnet\n",
        "opposite = []\n",
        "for syn in wordnet.synsets('depressed'):\n",
        "  for lem in syn.lemmas():\n",
        "    if lem.antonyms():\n",
        "     opposite.append(lem.antonyms()[0].name())\n",
        "opposite"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elate']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2h0EFZLapQz",
        "outputId": "0795ba44-34d9-4ebf-bcaf-c657303df33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# One more\n",
        "for syn in wordnet.synsets('ugly'):\n",
        "  for lem in syn.lemmas():\n",
        "    if lem.antonyms():\n",
        "      antonyms.append(lem.antonyms()[0].name())\n",
        "antonyms"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['elate', 'beautiful']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk7xzKCrbMcl"
      },
      "source": [
        "**Stemming NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTmNezqtb7Xa"
      },
      "source": [
        "# import PorterStemmer\n",
        "from nltk.stem import PorterStemmer\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHsCn1HRbRKk",
        "outputId": "c23f493e-99dd-44d9-a06b-b8d0073f37b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "ps=PorterStemmer()\n",
        "\n",
        "ps.stem('loving')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'love'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYcukTPCbN0L",
        "outputId": "4fcfb4ac-46a9-4eb3-9da3-ab1610dfba65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "ps.stem('trainee')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'traine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkfd6E0GcksH",
        "outputId": "cda213ef-38ec-4c95-8d23-b6e665934113",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "ps.stem('criteria')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'criteria'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnFkpmfQcsfo"
      },
      "source": [
        "**Stemming Words from Other Languages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGt3ppOhcuif",
        "outputId": "d7447feb-4b28-42fd-e8f0-83ea2dd45fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "# Display Languages\n",
        "from nltk.stem import SnowballStemmer\n",
        "SnowballStemmer.languages"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('arabic',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'hungarian',\n",
              " 'italian',\n",
              " 'norwegian',\n",
              " 'porter',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'spanish',\n",
              " 'swedish')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHSMxME3dVFq",
        "outputId": "032cd222-1f9d-4b68-871c-3cdf8e346833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "rom_stemmer = SnowballStemmer('german')\n",
        "rom_stemmer.stem('termin')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'termin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC3SlubreA-9"
      },
      "source": [
        "**Lemmatizing NLTK Using WordNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_VNeD5YeGBe",
        "outputId": "dd9c0ad4-d2b1-4fe5-fea9-608f1f844e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatizer.lemmatize('believes')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'belief'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNDTOEQSfGL0",
        "outputId": "5efa2456-03bf-4c79-8ad6-a1f7955a5b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "#  to work with a verb (believes) instead of a noun (belief), use the â€˜posâ€™ argument-\n",
        "lemmatizer.lemmatize('believes', pos='v')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'believe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnFXZfWTfgOQ",
        "outputId": "5362dfef-702f-45db-bb44-9ad7933161b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "# pos=v ==> verb\n",
        "# pos=n ==> noun\n",
        "lemmatizer.lemmatize('crossing', pos='v')\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cross'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cVBvimYfw5Y",
        "outputId": "40982172-9692-461d-cd8d-5cc7e378ab79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "# to get noun\n",
        "lemmatizer.lemmatize('crossing', pos='n')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'crossing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwy6QC6cf6-K"
      },
      "source": [
        ""
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5C_DoKaf72a"
      },
      "source": [
        "**NLTK Stop Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH-woN1sf9MI",
        "outputId": "7d3e644b-cbcb-4edb-8596-5680e44fb04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJS-7Bn8ggQt"
      },
      "source": [
        "text=\"Today is a great day. It is even better than yesterday. And yesterday was the best day ever!\""
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkWNo12PjAli",
        "outputId": "5d4a5d28-0bd7-47ee-8cae-92c5a4dd22a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))\n",
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(text)\n",
        "\n",
        "wordsFiltered = []\n",
        "for w in words:\n",
        "  if w not in stopwords:\n",
        "    wordsFiltered.append(w)\n",
        "\n",
        "wordsFiltered"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Today',\n",
              " 'great',\n",
              " 'day',\n",
              " '.',\n",
              " 'It',\n",
              " 'even',\n",
              " 'better',\n",
              " 'yesterday',\n",
              " '.',\n",
              " 'And',\n",
              " 'yesterday',\n",
              " 'best',\n",
              " 'day',\n",
              " 'ever',\n",
              " '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNn9PD7Uj7U2"
      },
      "source": [
        "**Speech Tagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5AbYPDdj6ey",
        "outputId": "5bc9b91f-e705-4540-ece1-727c72e31a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "text='I am a human being, capable of doing terrible things'\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "for s in sentences:\n",
        "  print(nltk.pos_tag(nltk.word_tokenize(s)))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('I', 'PRP'), ('am', 'VBP'), ('a', 'DT'), ('human', 'JJ'), ('being', 'VBG'), (',', ','), ('capable', 'JJ'), ('of', 'IN'), ('doing', 'VBG'), ('terrible', 'JJ'), ('things', 'NNS')]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}